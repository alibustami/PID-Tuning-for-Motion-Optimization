{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import chart_studio.plotly as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from numpy import array\n",
    "from src.utils.utils_funcs import load_init_states\n",
    "from pydantic import BaseModel, validator\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union, Tuple, Dict, Any\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f6/c9bxgxqd72ndbxyxv7_8mcrh0000gp/T/ipykernel_26155/744051963.py:46: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\n"
     ]
    }
   ],
   "source": [
    "class ParametersBounds(BaseModel):\n",
    "    Kp: Tuple[float, float]\n",
    "    Ki: Tuple[float, float]\n",
    "    Kd: Tuple[float, float]\n",
    "\n",
    "\n",
    "class Constraint(BaseModel):\n",
    "    overshoot: Tuple[float, float]\n",
    "    risetime: Tuple[float, float]\n",
    "\n",
    "\n",
    "class Gains(BaseModel):\n",
    "    Kp: float\n",
    "    Ki: float\n",
    "    Kd: float\n",
    "\n",
    "\n",
    "class TxtContent(BaseModel):\n",
    "    parameters_bounds: ParametersBounds\n",
    "    constraint: Constraint\n",
    "    n_iter: int\n",
    "    n_trials: int\n",
    "    experiment_total_run_time: int\n",
    "    experiment_values_dump_rate: int\n",
    "    selected_init_state: int\n",
    "    objective_value_limit_early_stop: float\n",
    "    total_exp_time: float\n",
    "    x: Gains\n",
    "    settling_time: int\n",
    "\n",
    "\n",
    "class Trial(BaseModel):\n",
    "    init_0_csv: Any\n",
    "    init_1_csv: Any\n",
    "    init_2_csv: Any\n",
    "    init_3_csv: Any\n",
    "    init_4_csv: Any\n",
    "    init_5_csv: Any\n",
    "    init_0_txt: Optional[TxtContent] = None\n",
    "    init_1_txt: Optional[TxtContent] = None\n",
    "    init_2_txt: Optional[TxtContent] = None\n",
    "    init_3_txt: Optional[TxtContent] = None\n",
    "    init_4_txt: Optional[TxtContent] = None\n",
    "    init_5_txt: Optional[TxtContent] = None\n",
    "\n",
    "    @validator(\n",
    "        \"init_0_csv\",\n",
    "        \"init_1_csv\",\n",
    "        \"init_2_csv\",\n",
    "        \"init_3_csv\",\n",
    "        \"init_4_csv\",\n",
    "        \"init_5_csv\",\n",
    "        pre=True,\n",
    "        always=True,\n",
    "    )\n",
    "    def validate_csv(cls, v):\n",
    "        if not isinstance(v, pd.DataFrame):\n",
    "            raise ValueError(\"CSV file must be a pandas DataFrame\")\n",
    "        return v\n",
    "\n",
    "\n",
    "class Config(BaseModel):\n",
    "    trial_1: Trial\n",
    "    # trial_2: Optional[Trial] = None\n",
    "    # trial_3: Optional[Trial] = None\n",
    "    configs_file: Path\n",
    "\n",
    "\n",
    "class OptimizerResults(BaseModel):\n",
    "    config_1: Config\n",
    "    config_2: Config\n",
    "    config_3: Config\n",
    "\n",
    "\n",
    "class DifferentialEvolutionResults(OptimizerResults):\n",
    "    pass\n",
    "\n",
    "\n",
    "class BayesianOptimizerResults(OptimizerResults):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = \"/Users/aalbustami/Ali/PID-Tuning-for-Motion-Optimization\"\n",
    "\n",
    "de_dir = os.path.join(BASE_PATH, \"DE-results\")\n",
    "bo_dir = os.path.join(BASE_PATH, \"BO-results\")\n",
    "\n",
    "de_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configs = [\"config_1\", \"config_2\", \"config_3\"]\n",
    "# trials = {\"config_1\": \"trial_1\", \"config_2\": \"trial_1\", \"config_3\": \"trial_1\"}\n",
    "# initializations = [f\"init_{i}\" for i in range(6)]\n",
    "# file_types = [\"csv\", \"txt\"]\n",
    "\n",
    "# # Function to generate the dictionary structure\n",
    "# def create_dict(configs, trials, initializations, file_types):\n",
    "#     return {\n",
    "#         config: {\n",
    "#             trial: {f\"{init}_{file_type}\": None for init in initializations for file_type in file_types}\n",
    "#             for trial in [trials[config]]\n",
    "#         }\n",
    "#         for config in configs\n",
    "#     }\n",
    "\n",
    "# # Create de_dict and do_dict using the function\n",
    "# de_dict = create_dict(configs, trials, initializations, file_types)\n",
    "# do_dict = create_dict(configs, trials, initializations, file_types)\n",
    "\n",
    "# print(de_dict)\n",
    "# print(do_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# de_dict = {\n",
    "#     \"config_1\": {\n",
    "#         \"trial_1\": {\n",
    "#             \"init_0_csv\": None,\n",
    "#             \"init_1_csv\": None,\n",
    "#             \"init_2_csv\": None,\n",
    "#             \"init_3_csv\": None,\n",
    "#             \"init_4_csv\": None,\n",
    "#             \"init_5_csv\": None,\n",
    "#             \"init_0_txt\": None,\n",
    "#             \"init_1_txt\": None,\n",
    "#             \"init_2_txt\": None,\n",
    "#             \"init_3_txt\": None,\n",
    "#             \"init_4_txt\": None,\n",
    "#             \"init_5_txt\": None,\n",
    "#         },\n",
    "#         \"configs_file\": None,\n",
    "#     },\n",
    "#     \"config_2\": {\n",
    "#         \"trial_1\": {\n",
    "#             \"init_0_csv\": None,\n",
    "#             \"init_1_csv\": None,\n",
    "#             \"init_2_csv\": None,\n",
    "#             \"init_3_csv\": None,\n",
    "#             \"init_4_csv\": None,\n",
    "#             \"init_5_csv\": None,\n",
    "#             \"init_0_txt\": None,\n",
    "#             \"init_1_txt\": None,\n",
    "#             \"init_2_txt\": None,\n",
    "#             \"init_3_txt\": None,\n",
    "#             \"init_4_txt\": None,\n",
    "#             \"init_5_txt\": None,\n",
    "#         },\n",
    "#         \"configs_file\": None,\n",
    "#     },\n",
    "#     \"config_3\": {\n",
    "#         \"trial_1\": {\n",
    "#             \"init_0_csv\": None,\n",
    "#             \"init_1_csv\": None,\n",
    "#             \"init_2_csv\": None,\n",
    "#             \"init_3_csv\": None,\n",
    "#             \"init_4_csv\": None,\n",
    "#             \"init_5_csv\": None,\n",
    "#             \"init_0_txt\": None,\n",
    "#             \"init_1_txt\": None,\n",
    "#             \"init_2_txt\": None,\n",
    "#             \"init_3_txt\": None,\n",
    "#             \"init_4_txt\": None,\n",
    "#             \"init_5_txt\": None,\n",
    "#         },\n",
    "#         \"configs_file\": None,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# do_dict = {\n",
    "#     \"config_1\": {\n",
    "#         \"trial_1\": {\n",
    "#             \"init_0_csv\": None,\n",
    "#             \"init_1_csv\": None,\n",
    "#             \"init_2_csv\": None,\n",
    "#             \"init_3_csv\": None,\n",
    "#             \"init_4_csv\": None,\n",
    "#             \"init_5_csv\": None,\n",
    "#             \"init_0_txt\": None,\n",
    "#             \"init_1_txt\": None,\n",
    "#             \"init_2_txt\": None,\n",
    "#             \"init_3_txt\": None,\n",
    "#             \"init_4_txt\": None,\n",
    "#             \"init_5_txt\": None,\n",
    "#         },\n",
    "#         \"configs_file\": None,\n",
    "#     },\n",
    "#     \"config_2\": {\n",
    "#         \"trial_1\": {\n",
    "#             \"init_0_csv\": None,\n",
    "#             \"init_1_csv\": None,\n",
    "#             \"init_2_csv\": None,\n",
    "#             \"init_3_csv\": None,\n",
    "#             \"init_4_csv\": None,\n",
    "#             \"init_5_csv\": None,\n",
    "#             \"init_0_txt\": None,\n",
    "#             \"init_1_txt\": None,\n",
    "#             \"init_2_txt\": None,\n",
    "#             \"init_3_txt\": None,\n",
    "#             \"init_4_txt\": None,\n",
    "#             \"init_5_txt\": None,\n",
    "#         },\n",
    "#         \"configs_file\": None,\n",
    "#     },\n",
    "#     \"config_3\": {\n",
    "#         \"trial_1\": {\n",
    "#             \"init_0_csv\": None,\n",
    "#             \"init_1_csv\": None,\n",
    "#             \"init_2_csv\": None,\n",
    "#             \"init_3_csv\": None,\n",
    "#             \"init_4_csv\": None,\n",
    "#             \"init_5_csv\": None,\n",
    "#             \"init_0_txt\": None,\n",
    "#             \"init_1_txt\": None,\n",
    "#             \"init_2_txt\": None,\n",
    "#             \"init_3_txt\": None,\n",
    "#             \"init_4_txt\": None,\n",
    "#             \"init_5_txt\": None,\n",
    "#         },\n",
    "#         \"configs_file\": None,\n",
    "#     },\n",
    "# }\n",
    "def generate_dict(configs, trials, init_files):\n",
    "    result_dict = {}\n",
    "\n",
    "    for config in configs:\n",
    "        result_dict[config] = {}\n",
    "        for trial in trials:\n",
    "            init_dict = {}\n",
    "            for init_file in init_files:\n",
    "                for i in range(6):\n",
    "                    key = f\"init_{i}_{init_file}\"\n",
    "                    init_dict[key] = None\n",
    "            result_dict[config][trial] = init_dict\n",
    "        result_dict[config][\"configs_file\"] = None\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# Example usage\n",
    "configs = [\"config_1\", \"config_2\", \"config_3\"]\n",
    "trials = [\"trial_1\"]\n",
    "init_files = [\"csv\", \"txt\"]\n",
    "\n",
    "de_dict = generate_dict(configs, trials, init_files)\n",
    "bo_dict = generate_dict(configs, trials, init_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_txt_file(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = file.read()\n",
    "        data = eval(data)\n",
    "        \n",
    "        if isinstance(data[\"x\"], np.ndarray):\n",
    "            data[\"x\"] = Gains(Kp=data[\"x\"][0], Ki=data[\"x\"][1], Kd=data[\"x\"][2])\n",
    "\n",
    "        \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALLOWED_CONFIGS = [f\"config_{i}\" for i in range(1, 4)]\n",
    "INIT_STATES = [f\"init_{i}\" for i in range(6)]\n",
    "FILE_TYPES = [\"csv\", \"txt\"]\n",
    "\n",
    "for root, dirs, files in os.walk(de_dir):\n",
    "    for file_ in files:\n",
    "        if not any(\n",
    "            allowed_config in root for allowed_config in ALLOWED_CONFIGS\n",
    "        ):\n",
    "            continue  # to skip config_4 and above\n",
    "\n",
    "        if \"configs\" in file_:\n",
    "            for config in ALLOWED_CONFIGS:\n",
    "                if config in root:\n",
    "                    de_dict[config][\"configs_file\"] = os.path.join(root, file_)\n",
    "\n",
    "            continue\n",
    "        config = root.split(os.sep)[-2]\n",
    "        trial = root.split(os.sep)[-1]\n",
    "        selected_file = (\n",
    "            \"_\".join(file_.split(\"-\")[-1].split(\"_\")[1:][:2])\n",
    "            + \"_\"\n",
    "            + file_.split(\"-\")[-1].split(\"_\")[-1].split(\".\")[1]\n",
    "        )\n",
    "        # de_dict[config][trial][selected_file] = os.path.join(root, file_)\n",
    "        if \"csv\" in file_:\n",
    "            de_dict[config][trial][selected_file] = pd.read_csv(os.path.join(root, file_))\n",
    "        elif \"txt\" in file_:\n",
    "            results = read_txt_file(os.path.join(root, file_))\n",
    "            de_dict[config][trial][selected_file] = results\n",
    "        \n",
    "        \n",
    "for root, dirs, files in os.walk(bo_dir):\n",
    "    for file_ in files:\n",
    "        if not any(\n",
    "            allowed_config in root for allowed_config in ALLOWED_CONFIGS\n",
    "        ):\n",
    "            continue  # to skip config_4 and above\n",
    "\n",
    "        if \"configs\" in file_:\n",
    "            for config in ALLOWED_CONFIGS:\n",
    "                if config in root:\n",
    "                    do_dict[config][\"configs_file\"] = os.path.join(root, file_)\n",
    "\n",
    "            continue\n",
    "        config = root.split(os.sep)[-2]\n",
    "        trial = root.split(os.sep)[-1]\n",
    "        selected_file = (\n",
    "            \"_\".join(file_.split(\"-\")[-1].split(\"_\")[1:][:2])\n",
    "            + \"_\"\n",
    "            + file_.split(\"-\")[-1].split(\"_\")[-1].split(\".\")[1]\n",
    "        )\n",
    "\n",
    "        # do_dict[config][trial][selected_file] = os.path.join(root, file_)\n",
    "        if \"csv\" in file_:\n",
    "            do_dict[config][trial][selected_file] = pd.read_csv(os.path.join(root, file_))\n",
    "        elif \"txt\" in file_:\n",
    "            results = read_txt_file(os.path.join(root, file_))\n",
    "            do_dict[config][trial][selected_file] = results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_results = DifferentialEvolutionResults(**de_dict)\n",
    "bo_results = BayesianOptimizerResults(**do_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   experiment_id     kp    ki      kd  overshoot  rise_time  settling_time  \\\n",
      "0              1  12.00  0.00  0.7800  19.877778        600           2200   \n",
      "1              2  19.50  0.43  0.0010  29.855556        500           5000   \n",
      "2              3  18.25  0.44  0.7525  28.955556        500           5000   \n",
      "\n",
      "                                        angle_values  set_point  \n",
      "0  [-0.11, 3.24, 9.89, 19.81, 34.05, 48.25, 66.09...         90  \n",
      "1  [0.58, 9.42, 23.11, 33.12, 47.68, 66.1, 84.97,...         90  \n",
      "2  [0.01, 6.16, 19.22, 31.09, 45.25, 62.62, 81.1,...         90  \n",
      "18.249985695121897\n"
     ]
    }
   ],
   "source": [
    "print(de_results.config_1.trial_1.init_1_csv)\n",
    "print(bo_results.config_1.trial_1.init_1_txt.x.Kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pid-tunner-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
